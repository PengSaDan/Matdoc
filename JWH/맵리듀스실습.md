hdfs에 업로드

`hdfs dfs -copyFromLocal /home/hadoop/Downloads/data.csv /user/cctv`

외부 lib추가해서 share → hadoop 파일에 있는 jar 모두 추가

### Mapper

```java
package exam;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class CctvMapper extends Mapper<Object, Text, Text, IntWritable>{
    //one 변수 선언 IntWritable이란 하둡 시스템에서 만들어 놓은 특별한 타입 
		//빅데이터 처리시 직렬화. 역직렬화 시 네트워크에 타고 갈 수 있도록 한다.
		//병렬로 작업했던 것이 직렬화할 수 있도록 한다.
		private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    @Override
    protected void map(Object key, Text value, Mapper<Object, Text, Text, 
    		IntWritable>.Context context) throws IOException, InterruptedException {

	      // ","으로 잘라서 1번째꺼
        String[] strs = value.toString().split(",");
        word.set(strs[1]);
				//map() 메서드는 출력을 위해 Context의 인스턴스를 제공한다. 
        context.write(word, one);
    }
}
```

### Reducer

```java
package exam;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class CctvReducer extends Reducer<Text, IntWritable, Text, IntWritable>{

	private IntWritable result =new IntWritable();

	@Override
		//중복을 허용하는 key의 형태로 입력받는다.
	protected void reduce(Text key, Iterable<IntWritable> values, 
			Reducer<Text, IntWritable, Text, IntWritable>.Context context ) 
					throws IOException, InterruptedException{
		int sum=0;
		for(IntWritable value : values)
			sum+=value.get();
		result.set(sum);
		context.write(key, result);
	}
}
```

### Main(job)

```java
package exam;

import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class CctvMain {
	public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {
		
		//hdfs를 제어하기 위해서는 Configuration객체를 생성하고 FileSystem의 get메서드로 
		//configureation객체를 전달해 FileSystem을 획득해야 한다. 
		//이때 Configuration은 하줍 환경설정 파일에 접근하기 위한 클래스이다.
		Configuration conf = new Configuration(); //하둡의 구성정보를 가졌다.
		Job job = Job.getInstance(conf, "cctv"); //"cctv"라는 이름의 job생성
		job.setJarByClass(CctvMain.class);
		
		job.setMapperClass(CctvMapper.class);
		job.setCombinerClass(CctvReducer.class);
		job.setReducerClass(CctvReducer.class);
		
		job.setOutputKeyClass(Text.class);
		job.setOutputValueClass(IntWritable.class);
		
		FileInputFormat.addInputPath(job, new Path(args[0])); //입력파일 지정
		FileOutputFormat.setOutputPath(job, new Path(args[1])); //목적지 파일 지정
		
		System.exit(job.waitForCompletion(true)? 0 : 1); //맵리듀스 job 제출
	}

}
```

jar파일 생성하기 : 프로젝트 jar파일로 export하기

- 하둡은 최적화된 네트워크 직렬화를 위해 자체적으로 기본 타입 셋을 제공한다.
    - Long → LongWritable
    - String → Text
    - Integer → IntWritable